{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:05:21.427730500Z",
     "start_time": "2023-11-19T14:04:59.427768700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from model import unet_model\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from functools import partial\n",
    "from utils import dice_coef, dice_bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T14:08:09.265711300Z",
     "start_time": "2023-11-19T14:08:09.252710600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Зададим размер batch и размер изображения\n",
    "BATCH_SIZE = 16\n",
    "IMG_SHAPE  = (256, 256)\n",
    "OUTPUT_SIZE = (960, 1280)\n",
    "\n",
    "CLASSES = 6\n",
    "\n",
    "#Цвета для отображения сегментации\n",
    "Colors = ['black',\n",
    "          'blue',\n",
    "          'green',\n",
    "          'sky',\n",
    "          'cyan',\n",
    "          'orange',\n",
    "          'pink',\n",
    "          'red']\n",
    "rgb_colors = [(0,   0,   0),\n",
    "              (0, 0,   255),\n",
    "              (0, 255,  0),\n",
    "              (0, 255,  0),\n",
    "              (0,   255, 0),\n",
    "              (0,   0,   255),\n",
    "              (255, 165, 0),\n",
    "              (255, 192, 203),\n",
    "              (0,   255, 255),\n",
    "              (255, 0,   255)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:45:13.963090800Z",
     "start_time": "2023-11-19T13:45:13.927541800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "images = sorted(glob.glob('./dataset/images/*.jpg'))\n",
    "masks = sorted(glob.glob('./dataset/masks/*.bmp'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:46:45.375380100Z",
     "start_time": "2023-11-19T13:46:45.343753200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "#Функция для загрузки изображения\n",
    "def load_img(image, mask):\n",
    "    #Загружаем и препроцессим изображения\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, IMG_SHAPE)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "\n",
    "    #Загружаем и препроцессим маски изображений\n",
    "    mask = tf.io.read_file(mask)\n",
    "    mask = tf.io.decode_bmp(mask)\n",
    "    # mask = tf.image.grayscale_to_rgb(mask) #Если маски сохранены в GRAY\n",
    "    mask = tf.image.rgb_to_grayscale(mask)\n",
    "    mask = tf.image.resize(mask, IMG_SHAPE)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
    "\n",
    "    #Сохраним маски для каждого класса\n",
    "    masks = []\n",
    "    for i in range(CLASSES):\n",
    "        masks.append(tf.where(tf.equal(mask, float(i)), 1.0, 0.0))\n",
    "    masks = tf.stack(masks, axis=2)\n",
    "    masks = tf.reshape(masks, IMG_SHAPE + (CLASSES,))\n",
    "    return image, masks\n",
    "\n",
    "#Аугментация изобажений\n",
    "def aug_img(image, masks):\n",
    "    random_crop = tf.random.uniform((), 0.3, 1)\n",
    "    image = tf.image.central_crop(image, random_crop)\n",
    "    masks = tf.image.central_crop(masks, random_crop)\n",
    "    random_flip = tf.random.uniform((), 0, 1)\n",
    "    if random_flip >= 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        masks = tf.image.flip_left_right(masks)\n",
    "    image = tf.image.resize(image, IMG_SHAPE)\n",
    "    masks = tf.image.resize(masks, IMG_SHAPE)\n",
    "    return image, masks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:54:42.002867900Z",
     "start_time": "2023-11-19T13:54:41.992909400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "#Формируем датасет\n",
    "dataset = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(images),\n",
    "                               tf.data.Dataset.from_tensor_slices(masks)))\n",
    "\n",
    "#Загружаем дату\n",
    "dataset = dataset.map(load_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "#Аугментация (увеличим датасет в 50 раз)\n",
    "# dataset = dataset.repeat(50)\n",
    "# dataset = dataset.map(aug_img, num_parallel_calls=tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:54:42.573559400Z",
     "start_time": "2023-11-19T13:54:42.427669300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "#Размер train выборки\n",
    "train_size = 1200\n",
    "\n",
    "#Делим на train и test\n",
    "train_dataset = dataset.take(train_size).cache()\n",
    "test_dataset = dataset.skip(train_size).take(len(dataset) - train_size).cache()\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:54:44.008217800Z",
     "start_time": "2023-11-19T13:54:43.994219400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#Функция для подсчёта DICE коэффициента\n",
    "def dice_coef(y_pred, y_true):\n",
    "    y_pred = tf.unstack(y_pred, axis=3)\n",
    "    y_true = tf.unstack(y_true, axis=3)\n",
    "    dice_summ = 0\n",
    "\n",
    "    for i, (a_y_pred, b_y_true) in enumerate(zip(y_pred, y_true)):\n",
    "        dice_calculate = (2 * tf.math.reduce_sum(a_y_pred * b_y_true) + 1) /\\\n",
    "         (tf.math.reduce_sum(a_y_pred + b_y_true) + 1)\n",
    "\n",
    "        dice_summ += dice_calculate\n",
    "    avg_dice = dice_summ/CLASSES\n",
    "    return avg_dice\n",
    "\n",
    "\n",
    "#Функция для подсчета DICE loss\n",
    "def dice_loss(y_pred, y_true):\n",
    "    d_loss = 1 - dice_coef(y_pred, y_true)\n",
    "    return d_loss\n",
    "\n",
    "\n",
    "#binary_crossentropy - дает хорошую сходимость модели при сбалансированном наборе данных\n",
    "#DICE - хорошо в задачах сегментации но плохая сходимость\n",
    "#Плохо сбалансированные данные, но хорошие реузьтаты:\n",
    "# Binary crossentropy + 0.25 * DICE\n",
    "\n",
    "def dice_bce_loss(y_pred, y_true):\n",
    "    total_loss = 0.25 * dice_loss(y_pred, y_true) + tf.keras.losses.binary_crossentropy(y_pred, y_true)\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:53:16.849159Z",
     "start_time": "2023-11-19T13:53:16.826162900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#Иницилизируем модель\n",
    "model = unet_model(IMG_SHAPE, CLASSES)\n",
    "\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "#Компилируем модель\n",
    "model.compile(optimizer='adam',\n",
    "                  loss=[dice_bce_loss],\n",
    "                  metrics=[dice_coef])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:55:15.027011400Z",
     "start_time": "2023-11-19T13:55:13.015014100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/75 [===>..........................] - ETA: 5:09 - loss: 0.9115 - dice_coef: 0.0964Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Karpo\\AppData\\Local\\Temp\\ipykernel_11764\\2367473858.py\", line 4, in <module>\n",
      "    model.fit(train_dataset,\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 1415, in get_graph_debug_info\n",
      "    pywrap_tfe.TFE_ContextGetGraphDebugInfo(self._handle, name, buffer_)\n",
      "MemoryError: bad allocation\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1160, in get_records\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "  File \"C:\\Users\\Karpo\\PycharmProjects\\cv_group6\\venv\\Lib\\site-packages\\executing\\executing.py\", line 163, in __init__\n",
      "  File \"C:\\Users\\Karpo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "SystemError: error return without exception set\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "#Обучение\n",
    "model.fit(train_dataset,\n",
    "          validation_data=test_dataset,\n",
    "          epochs=EPOCHS,\n",
    "          initial_epoch=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T13:56:16.483519600Z",
     "start_time": "2023-11-19T13:55:15.029013400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('./checkpoints/checkpoint_best_unet_like_model_10epochs')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
