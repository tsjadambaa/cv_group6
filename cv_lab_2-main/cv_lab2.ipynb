{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# поиск по ключевым точкам, получить peak coord\n",
    "\n",
    "def matchTemplate(path_img, path_pattern):\n",
    "    \n",
    "    # Load the input images\n",
    "    input_image = cv2.imread(path_img, 0)\n",
    "    pattern_template = cv2.imread(path_pattern, 0)\n",
    "\n",
    "    input_name = path_img[path_img.rfind('/') + 1:path_img.rfind('.jpg')]\n",
    "    pattern_name = path_pattern[path_pattern.rfind('/') + 1:path_pattern.rfind('.jpg')]                                                                     \n",
    "\n",
    "    path = './key_points'\n",
    "    is_exist  = os.path.exists('./key_points')\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    if not os.path.exists(path + '/input'):\n",
    "        os.mkdir(path + '/input')\n",
    "\n",
    "    if not os.path.exists(path + '/pattern'):\n",
    "        os.mkdir(path + '/pattern')\n",
    "\n",
    "    if not os.path.exists('./result'):\n",
    "        os.mkdir('./result')\n",
    "\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    input_kp, input_desc = sift.detectAndCompute(input_image, None)\n",
    "    input_image_kp = cv2.drawKeypoints(input_image, input_kp, input_image)\n",
    "    kp_input_name = 'key_points/input/kp_' + input_name + '.jpg'\n",
    "    cv2.imwrite(kp_input_name, input_image_kp)\n",
    "    \n",
    "    pattern_kp, pattern_desc = sift.detectAndCompute(pattern_template,None)\n",
    "    pattern_image_kp = cv2.drawKeypoints(pattern_template, pattern_kp, pattern_template)\n",
    "    kp_pattern_name = 'key_points/pattern/kp_' + pattern_name + '.jpg'\n",
    "    cv2.imwrite(kp_pattern_name, pattern_image_kp)\n",
    "\n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict()\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(input_desc, pattern_desc, k=2)\n",
    "\n",
    "    points = []\n",
    "\n",
    "\n",
    "    height, width =  input_image.shape\n",
    "    \n",
    "    r = 0\n",
    "    b = 0\n",
    "    l = width\n",
    "    t = height\n",
    "    \n",
    "    ratio = 0.4\n",
    "    for i, j in matches:\n",
    "        if i.distance < ratio*j.distance:\n",
    "            points.append(i)\n",
    "            \n",
    "            img1_idx = i.queryIdx\n",
    "            \n",
    "            (x, y) = input_kp[img1_idx].pt\n",
    "            if x > r:\n",
    "                r = math.floor(x) + 1\n",
    "            if x < l:\n",
    "                l = math.floor(x)\n",
    "            if y < t:\n",
    "                t = math.floor(y)\n",
    "            if y > b:\n",
    "                b = math.floor(y) + 1\n",
    "        \n",
    "    result = cv2.drawMatches(input_image, input_kp, pattern_template, pattern_kp, points, None)\n",
    "    cv2.imwrite('result/' + 'result_' + input_name + '.jpg', result)\n",
    "    \n",
    "\n",
    "    #cv2.imshow(\"result\", result)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    highlight_start = (l, t)\n",
    "    highlight_end = (r, b)\n",
    "    \n",
    "    return highlight_start, highlight_end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def show(input_image, pattern_template, highlight_start, highlight_end,row):\n",
    "    cv2.rectangle(input_image,(row[\"x1\"],row[\"y1\"]), (row[\"x2\"],row[\"y2\"]),(255,0,0), 2)\n",
    "    cv2.rectangle(input_image, highlight_start, highlight_end, 255, 2)\n",
    "    # Visualize the pattern template and resulting image\n",
    "    fig_instance, axes_arr = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Show the pattern template\n",
    "    axes_arr[0].imshow(pattern_template, cmap='gray')\n",
    "    axes_arr[0].set_title('Pattern Template')\n",
    "\n",
    "    # Show the input image with the highlighted match\n",
    "    axes_arr[1].imshow(input_image, cmap='gray')\n",
    "    axes_arr[1].set_title('Pattern Highlighted')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# iou\n",
    "\n",
    "def iou(row, highlight_start, highlight_end):\n",
    "    true_points_set = set([])\n",
    "    pred_points_set= set([])\n",
    "\n",
    "    for x in range(row[\"x1\"], row[\"x2\"]):\n",
    "        for y in range(row[\"y1\"], row[\"y2\"]):\n",
    "                true_points_set.add((x,y))\n",
    "\n",
    "        for x in range(highlight_start[0],highlight_end[0]):\n",
    "            for y in range(highlight_start[1], highlight_end[1]):\n",
    "                pred_points_set.add((x,y))\n",
    "    iou_metric = len(true_points_set.intersection(pred_points_set)) / len(true_points_set.union(pred_points_set))\n",
    "    return iou_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5228365384615384\n",
      "0.822673031026253\n",
      "0.7174857142857143\n",
      "0.2898717948717949\n",
      "0.8027156549520766\n",
      "0.44515197826456104\n",
      "0.8179614641962122\n",
      "0.6414894596336187\n",
      "0.20031400573872557\n",
      "0.48528278625366006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m row \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[0;32m     12\u001b[0m highlight_start, highlight_end \u001b[38;5;241m=\u001b[39mmatchTemplate(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/pattern/cropped_img_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m iou_metric \u001b[38;5;241m=\u001b[39m \u001b[43miou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhighlight_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhighlight_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(iou_metric)\n\u001b[0;32m     15\u001b[0m iou_array\u001b[38;5;241m.\u001b[39mappend(iou_metric)\n",
      "Cell \u001b[1;32mIn[33], line 13\u001b[0m, in \u001b[0;36miou\u001b[1;34m(row, highlight_start, highlight_end)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(highlight_start[\u001b[38;5;241m0\u001b[39m],highlight_end[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(highlight_start[\u001b[38;5;241m1\u001b[39m], highlight_end[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m---> 13\u001b[0m             pred_points_set\u001b[38;5;241m.\u001b[39madd((x,y))\n\u001b[0;32m     14\u001b[0m iou_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(true_points_set\u001b[38;5;241m.\u001b[39mintersection(pred_points_set)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(true_points_set\u001b[38;5;241m.\u001b[39munion(pred_points_set))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m iou_metric\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# загрузка изображений, перебор\n",
    "import statistics\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('dataset/annotation.csv', delimiter=';')\n",
    "dataset.head()\n",
    "iou_array=[]\n",
    "\n",
    "for i in range(0, 36):\n",
    "    row = dataset.iloc[i]\n",
    "    highlight_start, highlight_end =matchTemplate(f\"dataset/{row['id']}.jpg\", f\"dataset/pattern/cropped_img_{row['id']}.jpg\")\n",
    "    iou_metric = iou(row,highlight_start,highlight_end)\n",
    "    print(iou_metric)\n",
    "    iou_array.append(iou_metric)\n",
    "\n",
    "iou_mean = statistics.mean(iou_array)\n",
    "print(\"iou_mean\",iou_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
