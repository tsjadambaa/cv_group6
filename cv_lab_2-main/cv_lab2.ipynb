{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск по ключевым точкам, получить peak coord\n",
    "\n",
    "def matchTemplate(path_img, path_pattern):\n",
    "    \n",
    "    input_image = cv2.imread(path_img, 0)\n",
    "    pattern_template = cv2.imread(path_pattern, 0)\n",
    "\n",
    "    input_name = path_img[path_img.rfind('/') + 1:path_img.rfind('.jpg')]\n",
    "    pattern_name = path_pattern[path_pattern.rfind('/') + 1:path_pattern.rfind('.jpg')]                                                                     \n",
    "\n",
    "    path = './key_points'\n",
    "    is_exist  = os.path.exists('./key_points')\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    if not os.path.exists(path + '/input'):\n",
    "        os.mkdir(path + '/input')\n",
    "\n",
    "    if not os.path.exists(path + '/pattern'):\n",
    "        os.mkdir(path + '/pattern')\n",
    "\n",
    "    if not os.path.exists('./result'):\n",
    "        os.mkdir('./result')\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    input_kp, input_desc = sift.detectAndCompute(input_image, None)\n",
    "    \n",
    "    input_image_kp = cv2.drawKeypoints(input_image, input_kp, input_image)\n",
    "    kp_input_name = 'key_points/input/kp_' + input_name + '.jpg'\n",
    "    cv2.imwrite(kp_input_name, input_image_kp)\n",
    "    \n",
    "    pattern_kp, pattern_desc = sift.detectAndCompute(pattern_template,None)\n",
    "    \n",
    "    pattern_image_kp = cv2.drawKeypoints(pattern_template, pattern_kp, pattern_template)\n",
    "    kp_pattern_name = 'key_points/pattern/kp_' + pattern_name + '.jpg'\n",
    "    cv2.imwrite(kp_pattern_name, pattern_image_kp)\n",
    "\n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(input_desc, pattern_desc, k=2)\n",
    "\n",
    "    height, width =  input_image.shape\n",
    "    \n",
    "    r = 0\n",
    "    b = 0\n",
    "    l = width\n",
    "    t = height\n",
    "    \n",
    "    ratio = 0.4\n",
    "    points = []\n",
    "\n",
    "    for i, pair in enumerate(matches):\n",
    "        try:\n",
    "            m, n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                points.append(m)\n",
    "                img1_idx = m.queryIdx\n",
    "                (x, y) = input_kp[img1_idx].pt\n",
    "                if x > r:\n",
    "                    r = math.floor(x) + 1\n",
    "                if x < l:\n",
    "                    l = math.floor(x)\n",
    "                if y < t:\n",
    "                    t = math.floor(y)\n",
    "                if y > b:\n",
    "                    b = math.floor(y) + 1            \n",
    "\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "        \n",
    "    result = cv2.drawMatches(input_image, input_kp, pattern_template, pattern_kp, points, None)\n",
    "    cv2.imwrite('result/' + 'result_' + input_name + '.jpg', result)\n",
    "    \n",
    "\n",
    "    highlight_start = (l, t)\n",
    "    highlight_end = (r, b)\n",
    "    \n",
    "    return highlight_start, highlight_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# поиск по ключевым точкам, получить peak coord\n",
    "\n",
    "def matchTemplate(path_img, path_pattern):\n",
    "    \n",
    "    # Load the input images\n",
    "    input_image = cv2.imread(path_img, 0)\n",
    "    pattern_template = cv2.imread(path_pattern, 0)\n",
    "\n",
    "    input_name = path_img[path_img.rfind('/') + 1:path_img.rfind('.jpg')]\n",
    "    pattern_name = path_pattern[path_pattern.rfind('/') + 1:path_pattern.rfind('.jpg')]                                                                     \n",
    "\n",
    "    path = './key_points'\n",
    "    is_exist  = os.path.exists('./key_points')\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    if not os.path.exists(path + '/input'):\n",
    "        os.mkdir(path + '/input')\n",
    "\n",
    "    if not os.path.exists(path + '/pattern'):\n",
    "        os.mkdir(path + '/pattern')\n",
    "\n",
    "    if not os.path.exists('./result'):\n",
    "        os.mkdir('./result')\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    input_kp, input_desc = orb.detectAndCompute(input_image, None)\n",
    "    \n",
    "    input_image_kp = cv2.drawKeypoints(input_image, input_kp, input_image)\n",
    "    kp_input_name = 'key_points/input/kp_' + input_name + '.jpg'\n",
    "    cv2.imwrite(kp_input_name, input_image_kp)\n",
    "    \n",
    "    pattern_kp, pattern_desc = orb.detectAndCompute(pattern_template,None)\n",
    "    \n",
    "    pattern_image_kp = cv2.drawKeypoints(pattern_template, pattern_kp, pattern_template)\n",
    "    kp_pattern_name = 'key_points/pattern/kp_' + pattern_name + '.jpg'\n",
    "    cv2.imwrite(kp_pattern_name, pattern_image_kp)\n",
    "\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = 11, # 12\n",
    "                   key_size = 20,     # 20\n",
    "                   multi_probe_level = 1) #2\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(input_desc, pattern_desc, k=2)\n",
    "\n",
    "    height, width =  input_image.shape\n",
    "    \n",
    "    r = 0\n",
    "    b = 0\n",
    "    l = width\n",
    "    t = height\n",
    "    \n",
    "    ratio = 0.6\n",
    "    points = []\n",
    "\n",
    "    for i, pair in enumerate(matches):\n",
    "        try:\n",
    "            m, n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                points.append(m)\n",
    "                img1_idx = m.queryIdx\n",
    "                (x, y) = input_kp[img1_idx].pt\n",
    "                if x > r:\n",
    "                    r = math.floor(x) + 1\n",
    "                if x < l:\n",
    "                    l = math.floor(x)\n",
    "                if y < t:\n",
    "                    t = math.floor(y)\n",
    "                if y > b:\n",
    "                    b = math.floor(y) + 1            \n",
    "\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "        \n",
    "    result = cv2.drawMatches(input_image, input_kp, pattern_template, pattern_kp, points, None)\n",
    "    cv2.imwrite('result/' + 'result_' + input_name + '.jpg', result)\n",
    "    \n",
    "\n",
    "    highlight_start = (l, t)\n",
    "    highlight_end = (r, b)\n",
    "    \n",
    "    return highlight_start, highlight_end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def show(input_image, pattern_template, highlight_start, highlight_end,row):\n",
    "    cv2.rectangle(input_image,(row[\"x1\"],row[\"y1\"]), (row[\"x2\"],row[\"y2\"]),(255,0,0), 2)\n",
    "    cv2.rectangle(input_image, highlight_start, highlight_end, 255, 2)\n",
    "    # Visualize the pattern template and resulting image\n",
    "    fig_instance, axes_arr = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Show the pattern template\n",
    "    axes_arr[0].imshow(pattern_template, cmap='gray')\n",
    "    axes_arr[0].set_title('Pattern Template')\n",
    "\n",
    "    # Show the input image with the highlighted match\n",
    "    axes_arr[1].imshow(input_image, cmap='gray')\n",
    "    axes_arr[1].set_title('Pattern Highlighted')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# iou\n",
    "\n",
    "def iou(row, highlight_start, highlight_end):\n",
    "    true_points_set = set([])\n",
    "    pred_points_set= set([])\n",
    "\n",
    "    for x in range(row[\"x1\"], row[\"x2\"]):\n",
    "        for y in range(row[\"y1\"], row[\"y2\"]):\n",
    "                true_points_set.add((x,y))\n",
    "\n",
    "        for x in range(highlight_start[0],highlight_end[0]):\n",
    "            for y in range(highlight_start[1], highlight_end[1]):\n",
    "                pred_points_set.add((x,y))\n",
    "    iou_metric = len(true_points_set.intersection(pred_points_set)) / len(true_points_set.union(pred_points_set))\n",
    "    return iou_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5228365384615384\n",
      "0.822673031026253\n",
      "0.7174857142857143\n",
      "0.2898717948717949\n",
      "0.8027156549520766\n",
      "0.44515197826456104\n",
      "0.8179614641962122\n",
      "0.6414894596336187\n",
      "0.20031400573872557\n",
      "0.48528278625366006\n",
      "0.9105503650231386\n",
      "0.13234414263491684\n",
      "0.683666964171873\n",
      "0.5230048881833814\n",
      "0.6777272727272727\n",
      "0.677816353219579\n",
      "0.9192484008528785\n",
      "0.08418268840509893\n",
      "0.7012867647058824\n",
      "0.8021978021978022\n",
      "0.3259951430683138\n",
      "0.26783193277310924\n",
      "0.036183809482696054\n",
      "0.5562384044526901\n",
      "0.4989596337910945\n",
      "0.7505432420686659\n",
      "0.7129896907216495\n",
      "0.733117816091954\n",
      "0.6522010420241475\n",
      "0.4166666666666667\n",
      "0.47992224908737496\n",
      "0.7184048898600366\n",
      "0.5697674418604651\n",
      "0.7564674397859055\n"
     ]
    }
   ],
   "source": [
    "# загрузка изображений, перебор\n",
    "import statistics\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('dataset/annotation.csv', delimiter=';')\n",
    "dataset.head()\n",
    "iou_array=[]\n",
    "\n",
    "for i in range(0, 36):\n",
    "    row = dataset.iloc[i]\n",
    "    highlight_start, highlight_end =matchTemplate(f\"dataset/{row['id']}.jpg\", f\"dataset/pattern/cropped_img_{row['id']}.jpg\")\n",
    "    iou_metric = iou(row,highlight_start,highlight_end)\n",
    "    print(iou_metric)\n",
    "    iou_array.append(iou_metric)\n",
    "\n",
    "iou_mean = statistics.mean(iou_array)\n",
    "print(\"iou_mean\",iou_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
